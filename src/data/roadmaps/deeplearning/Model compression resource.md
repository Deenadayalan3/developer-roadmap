#  Model compression resource
Model compression is a technique that has gained a lot of attention in recent years. With the increasing popularity of deep learning and the large size of modern neural networks, model compression is becoming a vital resource for deploying deep learning models in resource-constrained environments.

In essence, model compression refers to the process of reducing the size of a neural network model without significantly affecting its accuracy. This can be achieved through various techniques such as pruning, quantization, and knowledge distillation.
More to know

- [Discrete Model Compression With Resource Constraint for Deep Neural Networks](https://www.youtube.com/watch?v=2S2M3TJYSks)
- [ Deep Learning Model Compression](https://www.youtube.com/watch?v=eoZIGLLeMsY)
- [Image Compression Models | Digital Image Processing](https://www.youtube.com/watch?v=YzWQ1dRTWVs&list=PLXOYj6DUOGrrjyRKpD0U0bIKGOXCAOHkE)
